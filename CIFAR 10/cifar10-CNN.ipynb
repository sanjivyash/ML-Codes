{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the GPU ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if(torch.cuda.is_available()):\n",
    "    device = torch.device('cuda:0')\n",
    "    print('Running on the GPU')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('Running on the CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries and Frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchvision.datasets.utils import download_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = False # since the data has been downloaded and saved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag:\n",
    "    url = 'http://files.fast.ai/data/cifar10.tgz'\n",
    "    download_url(url, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag:\n",
    "    with tarfile.open('cifar10.tgz') as  tar:\n",
    "        tar.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the Data only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airplane': 0,\n",
       " 'automobile': 1,\n",
       " 'bird': 2,\n",
       " 'cat': 3,\n",
       " 'deer': 4,\n",
       " 'dog': 5,\n",
       " 'frog': 6,\n",
       " 'horse': 7,\n",
       " 'ship': 8,\n",
       " 'truck': 9}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the key-value dictionary\n",
    "name = {}\n",
    "count = 0\n",
    "for file in os.listdir('./cifar10/train'):\n",
    "    name[file] = count\n",
    "    count += 1\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'airplane',\n",
       " 1: 'automobile',\n",
       " 2: 'bird',\n",
       " 3: 'cat',\n",
       " 4: 'deer',\n",
       " 5: 'dog',\n",
       " 6: 'frog',\n",
       " 7: 'horse',\n",
       " 8: 'ship',\n",
       " 9: 'truck'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = {}\n",
    "for val in name:\n",
    "    classes[name[val]] = val\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "if flag:\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "    for file in os.listdir('./cifar10/train'):\n",
    "        for image in tqdm(os.listdir('./cifar10/train/' + file)):\n",
    "            try:\n",
    "                path = './cifar10/train/' + file + '/' + image\n",
    "                img = torch.tensor(plt.imread(path))\n",
    "                label = name[file]\n",
    "                X_train.append(img)\n",
    "                y_train.append(label)\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testing data\n",
    "if flag:\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    for file in os.listdir('./cifar10/test'):\n",
    "        for image in tqdm(os.listdir('./cifar10/test/' + file)):\n",
    "            try:\n",
    "                path = './cifar10/test/' + file + '/' + image\n",
    "                img = torch.tensor(plt.imread(path))\n",
    "                label = name[file]\n",
    "                X_test.append(img)\n",
    "                y_test.append(label)\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag:\n",
    "    for index, data in enumerate([X_train, y_train, X_test, y_test]):\n",
    "        name = ''\n",
    "\n",
    "        if index % 2 == 0:\n",
    "            name += 'X_'\n",
    "            data = torch.stack(data)\n",
    "        else:\n",
    "            name += 'y_'\n",
    "            data = torch.tensor(data)\n",
    "\n",
    "        if index < 2:\n",
    "            name += 'train.pt'\n",
    "        else:\n",
    "            name += 'test.pt'\n",
    "\n",
    "        torch.save(data, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Saved Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.load('X_train.pt').permute(0,3,1,2)\n",
    "X_test = torch.load('X_test.pt').permute(0,3,1,2)\n",
    "y_train = torch.load('y_train.pt')\n",
    "y_test = torch.load('y_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].permute(1,2,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size: 50000\n",
      "Testing Size: 10000\n"
     ]
    }
   ],
   "source": [
    "print('Training Size:', len(y_train))\n",
    "print('Testing Size:', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imread(img, label):\n",
    "    print(classes[label.item()])\n",
    "    plt.imshow(img.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airplane\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imread(X_test[0], y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing Training Data into Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_indices(n, val_pct = 0.2, seed = 69):\n",
    "    val = (int)(n * val_pct)\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(n)\n",
    "    \n",
    "    return perm[val:], perm[:val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: 40000\n",
      "Validation Data: 10000\n"
     ]
    }
   ],
   "source": [
    "n = len(X_train)\n",
    "train_ind, val_ind = split_indices(n)\n",
    "print('Training Data:', len(train_ind))\n",
    "print('Validation Data:', len(val_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "data_train = TensorDataset(X_train, y_train)\n",
    "data_test = TensorDataset(X_test, y_test)\n",
    "\n",
    "# training data\n",
    "train_sample = SubsetRandomSampler(train_ind)\n",
    "train_dl = DataLoader(data_train,\n",
    "                      batch_size,\n",
    "                      sampler = train_sample)\n",
    "\n",
    "# validation data\n",
    "val_sample = SubsetRandomSampler(val_ind)\n",
    "val_dl = DataLoader(data_train,\n",
    "                    batch_size,\n",
    "                    sampler = val_sample)\n",
    "\n",
    "# test data\n",
    "test_dl = DataLoader(data_test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dl:\n",
    "    print(x.shape)\n",
    "    break\n",
    "    \n",
    "for x, y in val_dl:\n",
    "    print(x.shape)\n",
    "    break\n",
    "    \n",
    "for x, y in test_dl:\n",
    "    print(x.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 16, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    \n",
    "    nn.Conv2d(16, 32, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    \n",
    "    nn.Conv2d(32, 64, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    \n",
    "    nn.Conv2d(64, 128, 3, padding  = 1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    \n",
    "    nn.Flatten(),\n",
    "    nn.Linear(128, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "optimiser = optim.Adam(model.parameters(), lr = 1e-3)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimiser):\n",
    "    model.train()\n",
    "    avg_loss = 0\n",
    "    \n",
    "    for X_batch, y_batch in tqdm(train_dl):\n",
    "        model.zero_grad()\n",
    "        \n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        pred = model(X_batch)\n",
    "        loss = criterion(pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        loss = loss.cpu().detach().numpy()\n",
    "        avg_loss += loss.item()\n",
    "        \n",
    "        del X_batch, y_batch, pred, loss\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    avg_loss /= len(train_ind)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, criterion):\n",
    "    model.eval()\n",
    "    avg_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in tqdm(val_dl):\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            pred = model(X_batch)\n",
    "            loss = criterion(pred, y_batch)\n",
    "            \n",
    "            loss = loss.cpu().detach().numpy()\n",
    "            avg_loss += loss.item()\n",
    "            correct += torch.sum(torch.argmax(pred, axis = 1) == y_batch).item()\n",
    "            \n",
    "            del X_batch, y_batch, pred, loss\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    avg_loss /= len(val_ind)\n",
    "    acc = correct / len(val_ind)\n",
    "    del correct\n",
    "    \n",
    "    return avg_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, criterion, optimiser, epochs = 15):\n",
    "    train_loss_rec = []\n",
    "    val_loss_rec = []\n",
    "    val_acc_rec = []\n",
    "    max_acc = 0\n",
    "    best_model = model\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train(model, criterion, optimiser)\n",
    "        train_loss_rec.append(train_loss)\n",
    "        \n",
    "        val_loss, val_acc = evaluate(model, criterion)\n",
    "        val_loss_rec.append(val_loss)\n",
    "        val_acc_rec.append(val_acc)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss}  Val Loss: {val_loss}  Val Acc: {val_acc}\")\n",
    "        \n",
    "        if max_acc < val_acc:\n",
    "            best_model = model\n",
    "            max_acc = val_acc\n",
    "            \n",
    "    plt.plot(train_loss_rec)\n",
    "    plt.plot(val_loss_rec)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(val_acc_rec)\n",
    "    plt.show()\n",
    "    \n",
    "    return max_acc, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in tqdm(test_dl):\n",
    "            \n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            pred = model(X_batch)\n",
    "            correct += torch.sum(torch.argmax(pred, axis = 1) == y_batch).item()\n",
    "            \n",
    "            del X_batch, y_batch, pred\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    test_acc = correct / len(y_test)\n",
    "    del correct\n",
    "    \n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Sanity Check</b>: Evaluate the initial model on the validation set. The accuracy should be about 10%, the ideal for random predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a13e76d4fd3246c9b986061533688103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=79), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0.018212801909446717, 0.1074)\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(model, criterion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc, model = fit(model, criterion, optimiser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc, model = fit(model, criterion, optimiser, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser2 = optim.Adam(model.parameters(), lr = 1e-4)\n",
    "best_acc, model = fit(model, criterion, optimiser, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the best Val Acc Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc # validation acuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'cifar10-CNN.pty')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = nn.Sequential(\n",
    "    nn.Conv2d(3, 16, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    \n",
    "    nn.Conv2d(16, 32, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    \n",
    "    nn.Conv2d(32, 64, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    \n",
    "    nn.Conv2d(64, 128, 3, padding  = 1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    \n",
    "    nn.Flatten(),\n",
    "    nn.Linear(128, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (4): ReLU()\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (7): ReLU()\n",
       "  (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (9): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (10): ReLU()\n",
       "  (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (12): Flatten()\n",
       "  (13): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (14): ReLU()\n",
       "  (15): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "model2.load_state_dict(torch.load('cifar10-CNN.pty'))\n",
    "model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef99a26abacc4bb699dc7637cb46054b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=79), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Accuracy: 0.6981\n"
     ]
    }
   ],
   "source": [
    "print('Evaluation Accuracy:', evaluate(model2, criterion)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e237c1199e384160a0df5cfcb12e9d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=79), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.6887\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy:', test(model2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
